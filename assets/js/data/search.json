[ { "title": "RDKit을 활용한 ChEMBL 분자들 사이의 유사도 검색", "url": "/posts/RDKit%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-ChEMBL-%EB%B6%84%EC%9E%90%EB%93%A4-%EC%82%AC%EC%9D%B4%EC%9D%98-%EC%9C%A0%EC%82%AC%EB%8F%84-%EA%B2%80%EC%83%89/", "categories": "", "tags": "ChEMBL, RDKit, molecular similarity, Python, multiprocessing", "date": "2022-07-12 15:00:00 +0000", "snippet": "분자 유사도(molecular similarity)는 화학정보학(cheminformatics) 분야에서 관심있는 연구 주제 중 하나입니다. 이 문서에서는 ChEMBL 데이터베이스에서 분자 데이터를 가져와 RDKit을 활용하여 한 쌍의 분자에 대한 유사도를 계산하는 방법을 소개합니다. 그리고 좀 더 실질적인 활용 예제로 ChEMBL 전체 데이터베이스에서 유사한 분자를 검색하는 방법을 살펴 보겠습니다.ChEMBL에서 RDKit 분자 객체 추출ChEMBL은 약물과 유사한 특성을 가진 생리활성 분자의 화학 데이터베이스입니다.많은 연구자들의 노력으로 손수 큐레이팅된 이 분자 데이터베이스는 다양한 포멧의 덤프 파일이 온라인에 공개되어 있습니다.이 중 sqlite 포멧을 다운로드하고 데이터베이스를 열어 테이블을 확인해 봅시다.import wgetimport tarfileimport sqlite3import pandas as pdfileurl = 'https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/chembl_30_sqlite.tar.gz'wget.download(fileurl)with tarfile.open('chembl_30_sqlite.tar.gz') as chembl: dbfile = chembl.extractfile('chembl_30/chembl_30_sqlite/chembl_30.db') # chembl_30/chembl_30_sqlite/chembl_30.db -&gt; chembl_30.db with open('chembl_30.db', 'wb') as f: f.write(dbfile.read())chembldb = sqlite3.connect('chembl_30.db')tablecount = [ (table, count) for table, in chembldb.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall() for count, in chembldb.execute(f\"SELECT COUNT(*) FROM {table}\").fetchall()]aspddf = pd.DataFrame(tablecount, columns=['table', 'count'])print(aspddf.sort_values(by='count', ascending=False).reset_index(drop=True))chembldb.close()   table count 0 activities 19286751 1 activity_properties 7424248 2 chembl_id_lookup 4131045 3 compound_structural_alerts 4112274 4 compound_records 2786911 5 molecule_dictionary 2157379 6 compound_properties 2139763 7 compound_structures 2136187 8 molecule_hierarchy 2073423 9 … … 78 curation_lookup 3 79 version 1 ChEMBL의 30 version 데이터베이스는 80개의 테이블로 자세한 분자 정보를 제공하고 있습니다.이 문서에서는 분자 유사도 계산을 위해 compound_structures와 molecule_dictionary 테이블을 다루겠습니다.compound_structures는 분자 객체 molfile, molecule_dictionary는 분자 식별자 chembl_id를 담고 있으며두 테이블은 molregno key로 연결되어 있습니다.classDiagramdirection LRclass compound_structures { molregno (fk) bigint molfile : text standard_inchi : varchar standard_inchi_key : varchar canonical_smiles : varchar}class molecule_dictionary { ... chembl_id : varchar ... molregno (pk) bigint}compound_structures --&gt; molecule_dictionary : molregno이제 이 두 테이블을 molregno로 join 하고 (chembl_id, molfile) 쌍의 값을 하나 확인해 보겠습니다.chembldb = sqlite3.connect('chembl_30.db')for chemblid, molfile in chembldb.execute(\"\"\" SELECT molecule_dictionary.chembl_id, compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno\"\"\"): print(chemblid, molfile) breakchembldb.close()CHEMBL6329 RDKit 2D24 26 0 0 0 0 0 0 0 0999 V2000 5.2792 -2.0500 0.0000 C 0 0 0 0 0 0 0 0 0 0 0 0 5.7917 -2.3500 0.0000 N 0 0 0 0 0 0 0 0 0 0 0 0 ... 7.3417 -5.6417 0.0000 C 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 0 3 1 1 0...22 24 2 0M END위 출력된 결과에서 chembl_id는 CHEMBLXXXX 형태의 문자열로, 간단히 molfile의 식별자로 활용하겠습니다.그리고 molfile은 RDKit ~ END 사이 공백과 개행이 포함된 문자열로,Mol file 형식의 분자 표현입니다.molfile의 첫번째 라인 RDKit 2D 에 보이는 RDKit은 화학정보학 분야에서 널리 사용되는 분자 분석용 Python 라이브러리입니다.사실 compound_structures.molfile 값은 RDKit의 분자 객체를 Mol file 형식으로 덤프한 것입니다.그리고 이 덤프된 문자열로 다시 RDKit의 분자 객체, rdkit.Chem.rdchem.Mol의 인스턴스를 복원할 수 있습니다.from rdkit import Chemmolecule: Chem.rdchem.Mol = Chem.MolFromMolBlock(molfile)지금까지 ChEMBL 데이터베이스로부터 RDKit 분자 객체를 얻는 과정을 간략히 살펴 보았습니다.이제 RDKit의 도움을 받아 RDKit 분자 객체들 사이의 유사도를 계산해 보겠습니다.Molecular Fingerprinting과 Similarity분자의 구조 정보를 bit의 배열로 표현하는 방법을 Molecular fingerprinting 이라고 합니다.그리고 Molecular fingerprint 간의 유사도가 Molecular similarity 입니다.즉, Molecular similarity 란 Molecular fingerprint 간의 유사도를 뜻하며, 두 분자가 구조적으로 유사한 정도로 해석됩니다.분자의 특성은 분자의 구조에 기인하므로, 두 분자의 Molecular fingerprint가 유사하다면 분자 특성도 유사할 것이라고 추측할 수 있습니다.RDKit은 Molecular fingerprint를 생성하고 이들간 Molecular similarity를 계산하는, 현재까지 연구되고 있는 다양한 방법들을 함수로 제공하고 있습니다.그 중 RDKit 문서의 Fingerprinting and Molecular Similarity 섹션을 참고하여 가장 간단한 방법을 사용하는 예제를 작성해 보겠습니다.from rdkit import Chem, DataStructs# Step 0. Prepare a pair of molfileschembldb = sqlite3.connect('chembl_30.db')(chemblid1, molfile1), (chemblid2, molfile2) = chembldb.execute(\"\"\" SELECT molecule_dictionary.chembl_id, compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno LIMIT 2\"\"\").fetchall()chembldb.close()# Step 1. Get the `Mol` objectsmolobj1, molobj2 = [Chem.MolFromMolBlock(m) for m in (molfile1, molfile2)]# Step 2. Translate them to fingerprintsfingerprint1, fingerprint2 = [Chem.RDKFingerprint(m) for m in (molobj1, molobj2)]# Step 3. Calculate molecular similarity using the fingerprintsmolsim = DataStructs.FingerprintSimilarity(fingerprint1, fingerprint2)print(chemblid1, chemblid2, molsim) # CHEMBL6329 CHEMBL6328 0.8778280542986425Step 2의 rdkit.Chem.RDKFingerprint는 rdkit.Chem.rdchem.Mol 객체의 fingerprint를 구하는 함수로,알고리즘이 RDKit Fingerprints에 소개되어 있습니다.이 함수의 반환값 fingerprint 변수의 구조는 2048개 bit의 배열입니다.&gt;&gt;&gt; type(fingerprint1)rdkit.DataStructs.cDataStructs.ExplicitBitVect&gt;&gt;&gt; fingerprint1.GetNumBits()2048&gt;&gt;&gt; fingerprint1.ToBitString()'1110011100...그리고 Step 3의 rdkit.DataStructs.FingerprintSimilarity는 두 fingerprint간의 similariry를 0과 1 사이의 값으로 반환합니다.그런데 이 함수의 metric 인수를 명시하지 않을 경우, 기본값 rdkit.DataStructs.TanimotoSimilarity 가 similariry 계산에 사용되는데Tanimoto similarity 계산식은 이전 게시물에서 살펴본 Jaccard score와 동일합니다.\\[Tanimoto(A, B) = {| A \\cup B | \\over | A \\cap B |}\\]지금까지 분자 유사도 계산에 필요한 RDKit 함수를 간략히 소개하였습니다.이를 바탕으로 임의의 ChEMBL ID를 한 쌍 입력받아 유사도를 반환하는 함수를 작성한다면 대략적인 구조는 다음과 같은 형태가 될 것입니다.def chembl_similarity(chembl1: str, chembl2: str) -&gt; float: chembldb = sqlite3.connect('chembl_30.db') molfiles = chembldb.execute(f\"\"\" SELECT compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno AND molecule_dictionary.chembl_id IN ('{chembl1}', '{chembl2}') \"\"\") fingerprints = [Chem.RDKFingerprint(Chem.MolFromMolBlock(m)) for m, in molfiles] chembldb.close() assert len(fingerprints) == 2 return DataStructs.FingerprintSimilarity(*fingerprints)ChEMBL Similarity Search이론적인 분자 유사도 개념에 기반한 좀 더 실질적인 응용 사례는 분자 유사도 검색 (Molecular similarity search) 입니다.분자 유사도 검색이란 분자 하나를 입력받아 전체 데이터베이스에서 해당 분자와 특정값 이상의 유사도를 가지는 분자를 모두 찾는 것입니다.지금부터 ChEMBL 데이터베이스의 전체 분자들을 대상으로 이 동작을 구현해 봅시다.from typing import Iterablefrom tqdm import tqdmdef similar_chembls(querychembl: str, threshold: float) -&gt; Iterable[str]: \"\"\"`chemblquery`와 `threshold` 이상의 유사도를 가지는 ChEMBL 분자 검색. :param querychembl: ChEMBL 데이터베이스에서 분자의 identifier :param threshold: 0.0 ~ 1.0 사이의 유사도 lower bound :return: 순회 가능한 ChEMBL identifier 문자열 \"\"\" # Step 1. Fingerprints Cache 준비 chembldb = sqlite3.connect('chembl_30.db') fpcache = dict() for chemblid, molfile in tqdm(chembldb.execute(f\"\"\" SELECT molecule_dictionary.chembl_id, compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno \"\"\")): fpcache[chemblid] = Chem.RDKFingerprint(Chem.MolFromMolBlock(molfile)) chembldb.close() # Step 2. Filtering 처리 queryfp = fpcache[querychembl] return ( chembl for chembl, fp in fpcache.items() if DataStructs.FingerprintSimilarity(queryfp, fp) &gt;= threshold and chembl != querychembl )분자 유사도 검색 함수 similar_chembls의 구현은 크게 Fingerprints cache를 준비하고, Threshold filtering을 처리하는 두 부분으로 나누어집니다.이 구현은 직관적으로 이해가 쉽지만 성능에 문제가 있습니다. 각 Step의 시간 복잡도는 \\(O(n)\\) 으로 비교적 온건한 수준이지만,200만개 이상의 ChEMBL 분자에 대한 MolFromMolBlock, RDKFingerprint, FingerprintSimilarity 의 선형 처리가 완료 시간을 크게 지연시킵니다.특히 반복적인 similar_chembls 호출을 고려하여 Step 1의 fpcache는 이름처럼 Cache 될 필요가 있습니다.이와 같은 성능 문제를 개선하기 위해 먼저 Cache 파일을 준비해 보겠습니다.from pathlib import Pathimport multiprocessing as mpdef make_cache(): cachefile: Path = Path('chembl_30_fps.npz') # Step 1. Define and start parallel processing functions. def translate_fp(q_mf, q_fp): while True: mf = q_mf.get() if mf: id, mf = mf fp = Chem.RDKFingerprint(Chem.MolFromMolBlock(mf)) fp = np.array([bit == '1' for bit in fp.ToBitString()]) q_fp.put((id, fp)) else: return queue_mf = mp.Queue() queue_fp = mp.Queue() procnum = 48 procs = [mp.Process(target=translate_fp, args=(queue_mf, queue_fp)) for _ in range(procnum)] [proc.start() for proc in procs] # Step 2. Inject the parallel processing data into the queue. query = f\"\"\" SELECT molecule_dictionary.chembl_id, compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno \"\"\" chembldb, total = sqlite3.connect('chembl_30.db'), 0 for i, (chemblid, molfile) in tqdm(enumerate(chembldb.execute(query))): queue_mf.put((chemblid, molfile)) total = i + 1 chembldb.close() # Step 3. Gather all the parallel processed data from the queue. fpcache = [] for _ in tqdm(range(total)): fpcache.append(queue_fp.get()) [queue_mf.put(None) for _ in range(procnum)] [proc.join() for proc in procs] # Step 4. Dump results to the cache file. chemblids, fps = list(zip(*fpcache)) chemblids, fps = np.array(chemblids), np.array(fps) np.savez(cachefile, chemblids=chemblids, fps=fps)위 코드에서 Cache 생성 시간을 단축시키기 위해 Python multiprocessing 패키지의 병렬 처리를 적용하였습니다.그리고 Cache 데이터를 npz 파일로 덤프하기 위해 Fingerprint로 np.ndarray 형식이 사용된 점도 참고해 주세요.이제 이 Cache 파일을 활용하는 분자 유사도 검색부를 작성해 보겠습니다.from sklearn.metrics import jaccard_scoredef similar_chembls_new(querychembl: str, threshold: float) -&gt; Iterable[str]: cachefile: Path = Path('chembl_30_fps.npz') # Shared variables among child processes via the Copy-On-Write trick. with np.load(cachefile) as cachedata: chemblids = cachedata['chemblids'] fps = cachedata['fps'] chemblid_to_index = {chemblid: i for i, chemblid in enumerate(chemblids)} querychembl_index = chemblid_to_index[querychembl] querychembl_fp = fps[querychembl_index] def similariry_proc(q_inp, q_out): while True: index: int = q_inp.get() if index is not None: similarity = jaccard_score(querychembl_fp, fps[index]) q_out.put((index, similarity)) else: return queue_input = mp.Queue() queue_output = mp.Queue() procnum = 48 procs = [mp.Process(target=similariry_proc, args=(queue_input, queue_output)) for _ in range(procnum)] [proc.start() for proc in procs] for i in tqdm(range(len(chemblids))): queue_input.put(i) for _ in tqdm(range(len(chemblids))): idx, sim = queue_output.get() if sim &gt;= threshold and idx != querychembl_index: # Skip the self-comparing similarity yield chemblids[idx] [queue_input.put(None) for _ in range(procnum)] [proc.join() for proc in procs]similar_chembls_new에서는 make_cache와 유사한 병렬 처리 기법이 적용되었습니다.두 함수 모두 자식 프로세스들과 input/output 역할을 담당하는 mp.Queue를 통해 데이터를 송수신하며부모 프로세스는 None 값을 신호로 자식 프로세스들을 종료시킵니다.similar_chembls_new에서 좀 더 설명 드릴 부분이 두 가지 있습니다. 　첫째, querychembl_fp, fps 변수가 부모/자식 프로세스들 간 공유됩니다.이 기법은 POSIX 규격의 fork() 구현에 명세된 Copy-On-Write (COW) 를 활용한 것입니다.일반적으로 Inter-Process-Communication (IPC) 에서는 데이터를 직렬화하고 전송하는데 큰 오버헤드가 있습니다.따라서 자식 프로세스 similariry_proc들이 Fingerprint 전체 배열이 아니라 상대적으로 용량이 작은 fps의 index를 전달받도록 하여 IPC 오버헤드를 최소화하였습니다. 　둘째, 유사도 계산 시 RDKit FingerprintSimilarity 대신 scikit-learn의 jaccard_score를 사용하였습니다.표면적인 이유는 cachefile에 저장된 데이터가 Fingerprint의 ExplicitBitVect 객체가 아니라 1차원 np.ndarray 이기 때문이지만,사실 Fingerprint에 np.ndarray 형식을 사용한 것은Bit array 포멧의 Fingerprint, Tanimoto similarity와 동일한 Jaccard score, Jaccard score의 병렬 처리를준비하여 GPU 가속을 의도한 것입니다.지금은 이 문서 RDKit을 활용한 ChEMBL 분자들 사이의 유사도 검색 에서 다루는 주제의 범위를 고려하여COW 활용, GPU 가속 관련 내용은 근시일 내 별도의 게시물에서 자세히 소개해 드리도록 하겠습니다.Usage of Similarity Search Class지금까지 chembl_similarity, similar_chembls, make_cache, similar_chembls_new 를 통해ChEMBL Similarity Search 기능을 구현할 때 필요한 내용들을 모두 다루었습니다.아래 코드는 이 함수들의 구현을 이어 붙여 만든 가장 간단한 버전의 ChEMBL Similarity Search class의 예제로 참고 부탁 드립니다.import multiprocessing as mpimport sqlite3from pathlib import Pathfrom typing import Iterableimport numpy as npfrom rdkit import Chemfrom sklearn.metrics import jaccard_scorefrom tqdm import tqdmclass ChemblSimilaritySearch(object): def __init__(self): # Step 1. Fingerprints Cache 준비 cachefile = Path('chembl_30_fps.npz') if not cachefile.exists(): chemblsqlite = Path('chembl_30.db') def procfp(q_mf, q_fp): while True: mf = q_mf.get() if mf: id, mf = mf fp = Chem.RDKFingerprint(Chem.MolFromMolBlock(mf)) fp = np.array([bit == '1' for bit in fp.ToBitString()]) q_fp.put((id, fp)) else: return queue_mf = mp.Queue() queue_fp = mp.Queue() procnum = 48 procs = [mp.Process(target=procfp, args=(queue_mf, queue_fp)) for _ in range(procnum)] [proc.start() for proc in procs] query = f\"\"\" SELECT molecule_dictionary.chembl_id, compound_structures.molfile FROM molecule_dictionary, compound_structures WHERE molecule_dictionary.molregno = compound_structures.molregno \"\"\" chembldb, total = sqlite3.connect(chemblsqlite), 0 for i, (chemblid, molfile) in tqdm(enumerate(chembldb.execute(query))): queue_mf.put((chemblid, molfile)) total = i + 1 chembldb.close() fpcache = [] for _ in tqdm(range(total)): fpcache.append(queue_fp.get()) [queue_mf.put(None) for _ in range(procnum)] [proc.join() for proc in procs] chemblids, fps = list(zip(*fpcache)) chemblids, fps = np.array(chemblids), np.array(fps) np.savez(cachefile, chemblids=chemblids, fps=fps) with np.load(cachefile) as cachedata: self.chemblids = cachedata['chemblids'] self.fps = cachedata['fps'] self.chemblid_to_index = {chemblid: i for i, chemblid in enumerate(self.chemblids)} def __call__(self, querychembl: str, threshold: float) -&gt; Iterable[str]: # Step 2. Filtering 처리 querychembl_index = self.chemblid_to_index[querychembl] querychembl_fp = self.fps[querychembl_index] def procsim(q_inp, q_out): while True: index: int = q_inp.get() if index is not None: similarity = jaccard_score(querychembl_fp, self.fps[index]) q_out.put((index, similarity)) else: return queue_input = mp.Queue() queue_output = mp.Queue() procnum = 48 procs = [mp.Process(target=procsim, args=(queue_input, queue_output)) for _ in range(procnum)] [proc.start() for proc in procs] for i in range(len(self.chemblids)): queue_input.put(i) for _ in tqdm(range(len(self.chemblids))): idx, sim = queue_output.get() if sim &gt;= threshold and idx != querychembl_index: yield self.chemblids[idx] [queue_input.put(None) for _ in range(procnum)] [proc.join() for proc in procs]# 객체 생성하여 cache를 메모리에 적재chembl_similarity_search = ChemblSimilaritySearch()# 유사도 검색 사용 예for chemblid in chembl_similarity_search('CHEMBL6329', 0.9): print(chemblid)여담과 요약이 문서에는 화학정보학 분야의 논쟁적인 이슈가 포함되어 있습니다.많은 경우 분자의 2D 구조에 대한 유사도로 분자 특성을 예측하는 것이 타당하지 않으며, 분자 유사도 계산식으로 Tanimoto similarity는 너무 단순합니다.따라서 이 문서에서 다룬 분자 유사도 검색 방법이 그 학술적 의미를 대표하지 않음을 밝힙니다.다만 이 문서에서는 데이터 확보와 변환, 처리 속도 개선과 같은 아래의 프로그래밍 주제로 문맥을 전개하는데 해당 문제점들을 그대로 사용하였습니다. RDKit을 사용하여 ChEMBL 데이터베이스의 RDKit 2D molfile 값으로 Fingerprint 추출 Bit array 덤프 활용을 위해 Tanimoto similarity와 동일한 sklearn의 jaccard_score 사용multiprocessing은 병렬 처리를 위한 Python 내장 패키지로, 지금까지 살펴본 예제의Bit array 덤프와 유사도 검색 에서 여러 개의 자식 프로세스에 연산-집약적(CPU-bound) 동작을 위임하는데 활용되었습니다.이 때 부모 프로세스는 IPC 채널, multiprocessing.Queue 를 통해 처리할 데이터를 주입하고 처리된 데이터를 수집합니다.IPC는 데이터를 직렬화하고 전송하는데 오버헤드가 있어, Read-only 데이터에 COW를 활용하여 오버헤드를 경감시키는 방법도 살펴보았습니다.마지막으로 ChEMBL Similarity Search 기능을 담당하는 ChemblSimilaritySearch class를 작성하였습니다.이 class는 ChEMBL 전체 검색에 5분 이내의 시간이 소요됩니다.선형 처리에 비해 분명한 성능 개선이 있지만 웹서비스와 같은 실시간 응용을 고려하면 처리 시간을 더 단축시킬 필요가 있겠습니다.사실 예제를 제외한다면 이 문서의 주제는 ‘CPU 병렬 처리’라고 할 수 있습니다.곧 새로운 게시물에서 ‘GPU 병렬 처리’를 다루며 실시간성 측면에서 좀 더 실용적인 ChEMBL Similarity Search class를 소개드리도록 하겠습니다." }, { "title": "Numba로 Pairwise Jaccard score 계산 가속", "url": "/posts/Numba%EB%A1%9C-Pairwise-Jaccard-score-%EA%B3%84%EC%82%B0-%EA%B0%80%EC%86%8D/", "categories": "", "tags": "Python, Numba, Jaccard score", "date": "2022-06-28 15:00:00 +0000", "snippet": " Numba의 목적은 Python 함수의 실행 시간을 단축 시키는 것입니다. 이 문서에서는 binary array 들의 집합에서 모든 쌍의 Jaccard score 계산에 GPU 병렬 처리를 적용하여, 실행 시간이 얼마나 단축되는지 비교하겠습니다.먼저 이전 게시물을 참고하여scikit-learn 버전의 Pairwise Jaccard score 계산 동작을 구현해 보겠습니다.from typing import Iterable from sklearn.metrics import jaccard_score import itertools import numpy as np binarrs_number = 240 binarrs_bits = 160 binarrs = np.random.choice(2, size=(binarrs_number, binarrs_bits)) for a, b in itertools.combinations(binarrs, 2): print(jaccard_score(a, b))비교를 위해 동일한 binarrs를 입력받는 scikit-learn과 numba-gpu 버전의 두 함수를 준비합니다.def pjs_sklearn(binarrs: np.ndarray) -&gt; Iterable[float]: for a, b in itertools.combinations(binarrs, 2): yield jaccard_score(a, b) def pjs_nbgpu(binarrs: np.ndarray) -&gt; Iterable[float]: pass이제 pjs_nbgpu 함수 내부를 채워 봅시다.이전 게시물에서 살펴본 Numba GPU 함수의 호출부는 일종의 관용구로 모든 Numba GPU 함수는 동일한 형식을 따릅니다. 이 관용구를 활용해서 우선 pjs_nbgpu 형태를 잡아 보겠습니다.from numba import cuda def pjs_nbgpu(binarrs: np.ndarray) -&gt; Iterable[float]: @cuda.jit('void(uint64[:, :], uint64[:])') def inner_pjs_nbgpu(binarrs, out): pass length = len(binarrs) * (len(binarrs) - 1) // 2 _binarrs = cuda.to_device(binarrs) _out = cuda.device_array(length, np.float64) inner_pjs_nbgpu[length, 1](_binarrs, _out) out = _out.copy_to_host() yield from out그런데 pjs_nbgpu 내부에서 정의된 Numba GPU 함수, inner_pjs_nbgpu의 계산 결과값을 저장하는 out 버퍼의 크기는 얼마일까요? out 버퍼의 크기는 pjs_sklearn 함수의 반환값 순회인 itertools.combinations(n, 2)와 크기가 같아야 합니다. 이 값은 n개 원소 중 순서에 상관없이 2개의 원소를 선택하는 경우의 수, 즉\\[{}_nC_2 = {_nP_2 \\over 2!} = {n \\times (n - 1) \\over 2}\\]이므로, 이 수식으로 out 배열의 크기 length 를 구할 수 있습니다.위의 pjs_nbgpu 간략 버전에서 눈여겨봐야 할 또 한가지 중요한 부분은 Numba GPU 함수를 호출하는 구문inner_pjs_nbgpu[length, 1](_binarrs, _out) 입니다. Numba는 GPU 함수를 동시에 실행(multi-threading)하여 처리를 가속하는데, 이 때 배열 표기로 Thread의 갯수를 지정합니다. [length, 1]은 CUDA Programming Model에서 전체 block 중 length 개의 block을 사용하고, 한 block 당 1 개의 Thread를 생성한다는 뜻입니다. 즉, 이 구문에 의해 inner_pjs_nbgpu 함수는 out 배열의 크기인 $length \\times 1$ 개가 생성됩니다. 그리고 각 Thread(inner_pjs_nbgpu)들이 동시에 실행될 때 cuda.blockIdx.x 로 [0 ~ length-1] 범위의 숫자가 전달됩니다. 참고로 cuda.threadIdx.x 에는 배열 표기의 두 번째 원소로 고유값이 할당되는데, 이 예제에서는 그 범위가 [0 ~ (1–1)] 이므로 모든 Thread가 0 값의 cuda.threadIdx.x를 가지게 됩니다.@cuda.jit('void(uint64[:, :], uint64[:])') def inner_pjs_nbgpu(binarrs, out): thread_index = cuda.blockIdx.x a, b = combindex_of_iterttools(thread_index) out[thread_index] = pair_jaccard_score(a, b)위 코드는 inner_pjs_nbgp의 간소화 버전입니다. 가독성을 위해 combindex_of_iterttools, pair_jaccard_score 함수가 사용된 것을 확인해 주세요.모든 inner_pjs_nbgpu는 동시에 실행되면서 서로 다른 cuda.blockIdx.x 값으로 thread_index 값을 지정하고 out 배열에서 자신의 thread_index 자리에 pair_jaccard_score 계산 결과를 채웁니다.pair_jaccard_score 는 이전 게시물에서 다룬 Numba GPU 버전의 jaccard score 함수와 거의 동일하므로 combindex_of_iterttools 를 한 번 살펴보겠습니다.@cuda.jit('uint64(uint64, uint64)', device=True) def combindex_of_iterttools(_length, _index): i = _index m = n = _length - 1 while i &gt;= n: i -= n n -= 1 m -= n index_of_a = m index_of_b = m + i + 1 return index_of_a * _length + index_of_bcombindex_of_iterttools는 pjs_sklearn에서 사용하는 itertools.combinations(binarrs, 2) 를 모사하는데, thread_index를 binary array 배열 내의 인덱스 두 개로 매핑해 줍니다. 이 구현부는 선배님들의 지혜를 참고하였습니다.약간의 차이점은 Numba GPU 함수는 메모리 할당이 필요한 배열값을 반환할 수 없어, 두 개의 index 값을 하나의 uint64 변수로 반환하도록 반환값을 수정한 것 정도입니다.설명을 이어가기 전에 용어를 짧게 정리하겠습니다. 사실 지금까지 Python 함수와 구분짓기 위해 사용했던 Numba GPU 함수는 Kernel 함수라는 정확한 이름이 있습니다. Kernel 함수의 정의는 Python에서 호출되는 Numba GPU 함수입니다. 그리고 Kernel 함수에서 호출되는 Numba GPU 함수는 이와 구분짓기 위해 Device 함수라고 부릅니다. 그러니까 combindex_of_iterttools 는 Device 함수입니다. Device 함수는 cuda.jit decorator에 device=True 를 명시해야 하고, Kernel 함수와 달리 반환값을 가질 수 있다는 차이점이 있습니다.이제 지금까지 살펴본 내용을 합쳐 pjs_nbgpu 를 완성해 보겠습니다.def pjs_nbgpu(binarrs: np.ndarray) -&gt; Iterable[float]: @cuda.jit('uint64(uint64, uint64)', device=True) def combindex_of_iterttools(_length, _index): i = _index m = n = _length - 1 while i &gt;= n: i -= n n -= 1 m -= n index_of_a, index_of_b = m, m + i + 1 return index_of_a * _length + index_of_b @cuda.jit('float64(int64[:], int64[:])', device=True) def pair_jaccard_score(a, b): count_and, count_or = 0, 0 for i in range(len(a)): count_and += a[i] &amp; b[i] count_or += a[i] | b[i] return count_and / count_or @cuda.jit('void(int64[:, :], float64[:])') def inner_pjs_nbgpu(binarrs, out): thread_index = cuda.blockIdx.x _length = len(binarrs) ab = combindex_of_iterttools(_length, thread_index) a, b = ab // _length, ab % _length out[thread_index] = pair_jaccard_score(binarrs[a], binarrs[b]) length = len(binarrs) * (len(binarrs) - 1) // 2 _binarrs = cuda.to_device(binarrs) _out = cuda.device_array(length, np.float64) inner_pjs_nbgpu[length, 1](_binarrs, _out) out = _out.copy_to_host() yield from outPython 함수 pjs_nbgpu 는 두 개의 Device 함수, 하나의 Kernel 함수의 구현부와 Kernel 함수의 호출부로 구성됩니다. Kernel 함수는 binarrs 의 조합 갯수만큼 생성되어 전체 조합에 대한 Jaccard score가 동시에 계산됩니다. 계산된 결과는 itertools.combinations 의 순회 순서에 맞추어 1차원 배열 out 변수에 저장되고 모든 계산이 끝나면 pjs_nbgpu는 이 배열을 순회하며 값을 하나씩 반환합니다.import time start = time.time() result_of_pjs_sklearn = list(pjs_sklearn(binarrs)) seconds_of_pjs_sklearn = time.time() - start start = time.time() result_of_pjs_nbgpu = list(pjs_nbgpu(binarrs)) seconds_of_pjs_nbgpu = time.time() - start assert result_of_pjs_sklearn == result_of_pjs_nbgpu print(seconds_of_pjs_sklearn, seconds_of_pjs_nbgpu)&gt;&gt;&gt; 22.644657373428345 0.30959367752075195마지막으로 scikit-learn 버전과 비교하여, 계산값이 일치하고 계산 시간이 단축된 실험 결과를 확인할 수 있습니다.Numba는 Kernel 함수를 Multi-threading 하여 계산을 가속합니다. Kernel 함수의 Thread 갯수는 Kernel 함수 호출 시 [Block의 갯수, 한 Block의 Thread 갯수] 표현으로 (Block의 갯수) $ \\times $ (한 Block의 Thread 갯수) 를 지정합니다. Kernel 함수 호출 시 입력되는 인수는 모든 Thread가 공유하며 각 Thread는 고유 인덱스를 cuda.blockIdx, cuda.threadIdx로 전달 받아 자신의 업무를 처리할 수 있습니다.이 문서의 Pairwise Jaccard score 예제에서는 하나의 binary array pair에 대한 Jaccard score 계산을 Kernel 함수로 만들고, 이 Kernel 함수를 Multi-threading 하는 방법을 살펴 보았습니다. 이 때 전체 pairwise 갯수만큼 생성된 각 Thread는 자신 고유의 값 BlockIdx로 계산할 binary array pair와 결과값 저장 위치를 구함으로써모든 Thread가 서로 독립적인 작업을 한 번에 완료하는 것으로 계산 가속의 이득을 얻었습니다." }, { "title": "Numba의 GPU 처리를 활용한 Jaccard score 계산", "url": "/posts/Numba%EC%9D%98-GPU-%EC%B2%98%EB%A6%AC%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-Jaccard-score-%EA%B3%84%EC%82%B0/", "categories": "", "tags": "Python, Numba, Jaccard score", "date": "2022-06-23 15:00:00 +0000", "snippet": " Numba는 Numpy 배열 연산을 빠르게 처리하는데 특화된 Python package 입니다. 이 문서에서는 Jaccard score 계산 예제를 통해 Numba로 GPU 처리를 활용하는 방법을 소개합니다.Jaccard score는 두 집합의 유사한 정도를 측정하는 방법 중 하나로 $J(A, B) = {| A \\cup B | \\div | A \\cap B |}$ 로 계산되며 0과 1 사이의 값을 가집니다. Python에서 Jaccard score를 계산하는 가장 간단한 방법은 scikit-learn의 jaccard_score 함수를 호출하는 것입니다.from sklearn.metrics import jaccard_score import numpy as np a = np.random.choice(2, size=8) # [0 1 0 1 1 1 0 0] b = np.random.choice(2, size=8) # [0 0 1 0 1 1 1 1] print(jaccard_score(a, b)) # 0.2857142857142857Numba는 Python으로 작성된 함수를 GPU에서 호출 가능한 함수로 변환하는데, 이 때 변환될 Python 함수를 구현하고 호출하는데 몇가지 규칙이 있습니다. 이 규칙들을 살펴보기 위해 Jaccard score 계산식을 참고하여 simple_jaccard_score를 다음과 같이 구현해 보았습니다.def simple_jaccard_score(a: np.ndarray, b: np.ndarray) -&gt; float: count_and, count_or = 0, 0 for i in range(len(a)): count_and += a[i] &amp; b[i] count_or += a[i] | b[i] return count_and / count_or이제 simple_jaccard_score를 약간 수정하여 Numba GPU 함수로 만들어 보겠습니다.from numba import cuda @cuda.jit('void(int64[:], int64[:], float64[:])') def gpu_jaccard_score(a, b, out): count_and, count_or = 0, 0 for i in range(len(a)): count_and += a[i] &amp; b[i] count_or += a[i] | b[i] out[0] = count_and / count_orgpu_jaccard_score에서 살펴볼 Numba GPU 함수의 구현 규칙은 다음과 같습니다. GPU에서 실행할 함수에 numba.cuda.jit decorator를 사용합니다. numba.cuda.jit decorator의 첫번째 인수(signature)는 생략 가능하지만, Numba GPU 함수에서 사용할 수 없는 type hint를 대체할 수 있습니다. Numba GPU 함수는 Python과 Numpy의 기본 연산으로 작성되어야 합니다. Numba GPU 함수는 return을 사용하지 않고, 인수로 입력받은 버퍼에 계산 결과를 채우는 방식으로 값을 반환해야 합니다.그 다음 gpu_jaccard_score를 실행시켜 보고 Numba GPU 함수의 호출 규칙을 살펴 보겠습니다._a = cuda.to_device(a) _b = cuda.to_device(b) _out = cuda.device_array(1, np.float64) gpu_jaccard_score[1, 1](_a, _b, _out) print(_out.copy_to_host()) # [0.28571429] 우선 Numba GPU 함수에 입력될 인수를 GPU 배열 변수로 만듭니다. cuda.to_device는 Numpy 배열을 복사하고, cuda.device_array는 빈 배열을 생성합니다. Numba GPU 함수를 호출할 때 함수이름과 인수목록 사이에 배열 표기로 Thread의 갯수를 지정합니다. 지금은 하나의 Thread가 동작한다는 것 정도로만 참고해 주세요. Numba GPU 함수가 종료된 후 반환값이 저장된 GPU 배열 변수에서 cuda.copy_to_host로 저장된 값을 가져옵니다.이제 gpu_jaccard_score 의 구현부와 호출부를 합치면서 sklearn.metrics.jaccard_score 와 입출력을 맞추겠습니다.def numba_gpu_jaccard_score(a: np.ndarray, b: np.ndarray) -&gt; float: @cuda.jit('void(int64[:], int64[:], float64[:])') def gpu_jaccard_score(a, b, out): count_and, count_or = 0, 0 for i in range(len(a)): count_and += a[i] &amp; b[i] count_or += a[i] | b[i] out[0] = count_and / count_or _a = cuda.to_device(a) _b = cuda.to_device(b) _out = cuda.device_array(1, np.float64) gpu_jaccard_score[1, 1](_a, _b, _out) return _out.copy_to_host()[0]마지막으로 새롭게 작성된 Numba GPU 버전의 jaccard score 함수, numba_gpu_jaccard_score가 제대로 동작하는지 확인합니다.for _ in range(10): a = np.random.choice(2, size=8) b = np.random.choice(2, size=8) assert jaccard_score(a, b) == numba_gpu_jaccard_score(a, b)지금까지 Numba GPU 함수를 작성하는 규칙을 크게 구현부와 호출부로 나누어 살펴 보았습니다. 이 문서에서는 다루지 못했지만, Numba GPU 함수 작성 규칙과 관련한 좀 더 심도 있는 내용은 아래 Numba 공식 문서를 참고해 주세요 Decorator, numba.cuda.jit 의 명세 numba.cuda.jit의 첫번째 인수, signature 기입 방법 Numba GPU 함수 작성 시 사용할 수 있는 Python 기능" } ]
